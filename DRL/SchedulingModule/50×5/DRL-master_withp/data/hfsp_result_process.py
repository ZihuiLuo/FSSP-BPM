import numpy as np
import pandas as pd
import tensorflow as tf


def seem_equal(a, b):
    return sum(abs(a - b)) < 1e-5


# 本方法将归一化input test data反正规化，还原并返回原始数据
def norm_inverse(path):
    stage_num = 10
    columns = ['demand']
    p = ['p' + str(i + 1) for i in range(stage_num)]
    columns.extend(p)
    #columns = ['demand','p1','p2','p3','p4','p5']
    df = pd.DataFrame(path, columns=columns)
    # 反正规化
    without_norm = pd.read_csv("test_without_norm.csv")
    norm_inverse = lambda x, low, high: (x * (high - low) + low)
    low = {name: without_norm[name].min() for name in columns[1:]}
    high = {name: without_norm[name].max() for name in columns[1:]}
    new_df = {name: norm_inverse(df[name], low[name], high[name]) for name in columns[1:]}
    new_df = pd.DataFrame(new_df)
    new_df['demand'] = df['demand']
    #order = ['demand','p1','p2','p3','p4','p5']
    new_df = new_df[columns]
    return new_df


def update_start_end_time1(idx, stage):
    global end_time, start_time, depot_num
    """
    end_time: tensor of shape (stage_num, batch_size, cust_num)
    process_time: tensor of shape (batch_size, cust_num, stage_num)
    idx: cust_num selected, tensor of shape (depot_num, node_num, batch_size)
    stage: int
    """

    # # print(self.input_data)
    # # batch_size, node,_ = self.input_data.shape.as_list()
    # print("batch_size=",batch_size)
    def modify1(tensor, index, value):
        shape = tf.shape(tensor)
        return tensor - tensor[index] * tf.one_hot(index, shape[0]) + value * tf.one_hot(index, shape[0])

        # tensor，index都是二维，value标量

    def modify2(tensor, index, value):
        return tf.concat([tensor[:index[0]],
                          tf.expand_dims(
                              modify1(tensor[index[0]], index[1], value), axis=0),
                          tensor[index[0] + 1:]],
                         axis=0)

        # tensor，index都是三维，value标量

    def modify3(tensor, index, value):
        return tf.concat([tensor[:index[0]],
                          tf.expand_dims(
                              modify2(tensor[index[0]], index[1:], value), axis=0),
                          tensor[index[0] + 1:]],
                         axis=0)

    batch = 0
    n = batch_size

    def cond(batch, n, end_time, start_time):
        return batch < n

    def body(batch, n, end_time, start_time):

        node_list = idx[:, batch]


        node_list = tf.map_fn(
            lambda node: tf.cast(node, dtype=tf.int32),
            node_list, dtype=tf.int32)


        process_time_node = tf.map_fn(lambda node: process_time[batch, node, stage],
                                      node_list, dtype=tf.float32)
        # 选择的订单对应的结束时间，下标为node
        end_time_node = tf.zeros(node_num - 1)

        end_time_node = modify1(end_time_node, 0,
                                tf.reduce_max(
                                    [(end_time[
                                          stage - 1, batch, node_list[0]] if stage != 0 else 0.)
                                        , 0.], axis=0)
                                + process_time_node[0])
        # 第i个结点的结束时间为（max（自身上一个阶段的结束时间，上一个结点的结束时间）+ 其process_time）
        for i in range(1, node_num - 1):
            end_time_node = modify1(end_time_node, i,
                                    tf.reduce_max(
                                        [(end_time[
                                              stage - 1, batch, node_list[
                                                  i]] if stage != 0 else 0.),
                                         end_time_node[i - 1]],
                                        axis=0) +
                                    process_time_node[i])

        for i in range(node_num - 1):
            end_time = modify3(end_time, (stage, batch, node_list[i]), end_time_node[i])
            start_time = modify3(start_time, (stage, batch, node_list[i]),
                                 end_time_node[i] - process_time_node[i])

        batch = batch + 1
        return batch, n, end_time, start_time

    batch, n, end_time, start_time = tf.while_loop(cond, body, [batch, n, end_time, start_time])


# 测试时正规化的输入数据
list =[[10.0, 0.7234042, 0.68367344, 0.49484536, 0.7604167, 0.20408164, 0.67741936, 0.03125, 0.75, 0.14736842, 0.4456522], [10.0, 0.69148934, 0.41836736, 0.185567, 0.78125, 0.0, 0.8064516, 0.8645833, 0.6195652, 0.75789475, 0.5], [10.0, 0.79787236, 0.040816326, 0.4226804, 0.020833334, 0.52040815, 0.31182796, 0.9895833, 0.097826086, 0.47368422, 0.57608694], [10.0, 0.43617022, 0.75510204, 0.6185567, 0.78125, 0.29591838, 0.83870965, 0.0, 0.51086956, 0.77894735, 0.0], [10.0, 0.0, 0.010204081, 0.36082473, 0.6354167, 0.06122449, 0.41935483, 1.0, 1.0, 0.44210526, 0.010869565], [10.0, 0.5319149, 0.08163265, 0.742268, 0.38541666, 0.15306123, 0.5591398, 0.7395833, 0.8913044, 0.2631579, 0.10869565], [10.0, 0.11702128, 0.2755102, 0.082474224, 0.7083333, 0.5408163, 0.6666667, 0.1875, 0.42391303, 0.2, 0.98913044], [10.0, 0.63829786, 0.9183673, 0.082474224, 0.14583333, 0.18367347, 0.8924731, 0.41666666, 0.95652175, 0.6, 0.19565217], [10.0, 0.79787236, 0.75510204, 0.36082473, 0.33333334, 0.19387755, 0.32258064, 0.78125, 0.9130435, 0.57894737, 0.75], [10.0, 0.82978725, 0.7244898, 0.072164945, 0.8020833, 0.81632656, 0.043010753, 0.9479167, 0.65217394, 0.0, 0.67391306], [10.0, 0.095744684, 0.20408164, 1.0, 0.84375, 1.0, 0.5483871, 0.40625, 0.6195652, 0.0, 0.9782609], [10.0, 0.7553192, 0.64285713, 0.52577317, 0.78125, 0.3265306, 0.6236559, 0.78125, 0.20652173, 0.6526316, 0.07608695], [10.0, 0.9787234, 0.19387755, 0.44329897, 0.16666667, 0.3265306, 0.24731183, 0.13541667, 0.7826087, 0.44210526, 0.7717391], [10.0, 0.25531915, 0.3877551, 0.082474224, 0.36458334, 0.2244898, 0.2580645, 0.27083334, 0.90217394, 0.47368422, 0.2826087], [10.0, 0.19148937, 0.6632653, 0.0, 0.072916664, 0.5816327, 0.8494624, 0.22916667, 0.41304347, 0.3263158, 0.98913044], [10.0, 0.11702128, 0.9285714, 0.0927835, 0.75, 0.1632653, 0.17204301, 0.33333334, 0.08695652, 0.85263157, 0.7173913], [10.0, 0.12765957, 0.63265306, 0.0927835, 0.9791667, 0.25510204, 0.65591395, 0.44791666, 0.5217391, 0.22105263, 0.13043478], [10.0, 0.10638298, 0.6632653, 0.58762884, 0.28125, 0.30612245, 0.5591398, 0.6770833, 0.07608695, 0.18947369, 0.1521739], [10.0, 0.70212764, 0.5102041, 0.83505154, 0.44791666, 0.9489796, 0.15053764, 0.16666667, 0.70652175, 0.15789473, 0.4456522], [10.0, 0.9680851, 0.35714287, 0.5154639, 0.5833333, 0.93877554, 0.29032257, 0.47916666, 0.8913044, 0.8842105, 0.26086956], [10.0, 0.64893615, 0.1632653, 0.34020618, 0.072916664, 0.020408163, 0.4516129, 0.59375, 0.19565217, 0.85263157, 0.8913044], [10.0, 0.11702128, 0.12244898, 0.83505154, 0.1875, 0.9183673, 0.23655914, 0.46875, 0.8152174, 0.05263158, 0.02173913], [10.0, 0.07446808, 0.70408165, 0.556701, 0.7083333, 0.29591838, 0.9354839, 0.15625, 0.5652174, 0.8842105, 0.06521739], [10.0, 0.34042552, 0.7346939, 0.46391752, 0.25, 0.39795917, 0.0, 0.7083333, 0.054347824, 0.33684212, 0.95652175], [10.0, 0.3617021, 0.93877554, 0.10309278, 0.1875, 0.9183673, 0.68817204, 0.17708333, 0.26086956, 0.29473683, 0.8804348], [10.0, 0.18085106, 0.06122449, 0.73195875, 0.6354167, 0.040816326, 0.5913978, 0.46875, 0.06521739, 0.57894737, 0.25], [10.0, 0.5851064, 0.10204082, 0.87628865, 0.13541667, 0.79591835, 0.75268817, 0.5104167, 0.8695652, 0.55789477, 0.82608694], [10.0, 0.79787236, 0.6020408, 0.0927835, 0.0, 0.40816328, 0.37634408, 0.35416666, 0.41304347, 0.07368421, 0.02173913], [10.0, 0.18085106, 0.7244898, 0.49484536, 0.45833334, 0.010204081, 0.21505377, 0.21875, 0.76086956, 0.12631579, 1.0], [10.0, 0.44680852, 1.0, 0.7010309, 0.114583336, 0.75510204, 0.21505377, 1.0, 0.90217394, 0.021052632, 0.07608695], [10.0, 0.89361703, 0.6020408, 0.82474226, 0.27083334, 0.5102041, 0.5268817, 0.5729167, 0.36956522, 0.6526316, 0.7282609], [10.0, 0.41489363, 0.78571427, 0.7628866, 0.9791667, 0.68367344, 0.58064514, 0.21875, 0.13043478, 0.76842105, 0.95652175], [10.0, 0.86170214, 1.0, 0.0927835, 1.0, 0.1632653, 0.9569892, 0.8333333, 0.08695652, 0.9052632, 0.65217394], [10.0, 0.27659574, 0.26530612, 0.28865978, 0.6041667, 0.46938777, 0.9354839, 0.041666668, 0.3152174, 0.22105263, 0.3043478], [10.0, 0.86170214, 0.877551, 0.62886596, 0.8958333, 0.53061223, 0.11827957, 0.6979167, 0.6304348, 0.9263158, 0.6413044], [10.0, 0.5425532, 0.0, 0.5670103, 0.9375, 0.622449, 1.0, 0.5625, 0.010869565, 0.8842105, 0.02173913], [10.0, 0.70212764, 0.020408163, 0.6597938, 0.3125, 0.622449, 0.06451613, 0.16666667, 0.95652175, 0.77894735, 0.57608694], [10.0, 0.20212767, 0.5714286, 0.6597938, 0.38541666, 0.06122449, 0.47311828, 0.44791666, 0.5, 0.18947369, 0.19565217], [10.0, 0.61702126, 0.30612245, 0.35051546, 0.7916667, 0.97959185, 0.43010753, 0.42708334, 0.39130434, 0.5263158, 0.29347825], [10.0, 0.7553192, 0.56122446, 0.21649484, 0.7291667, 0.18367347, 0.24731183, 0.21875, 0.9456522, 0.05263158, 0.8043478], [10.0, 0.9893617, 0.75510204, 0.39175257, 0.39583334, 0.08163265, 0.5591398, 0.6145833, 0.33695653, 0.5368421, 0.48913044], [10.0, 0.34042552, 0.21428572, 0.36082473, 0.5833333, 0.68367344, 0.6451613, 0.8958333, 0.4021739, 0.17894737, 0.29347825], [10.0, 0.71276593, 0.7244898, 0.69072163, 0.072916664, 0.23469388, 0.61290324, 0.6770833, 0.18478261, 0.5368421, 0.82608694], [10.0, 0.67021275, 0.29591838, 0.96907216, 0.35416666, 0.31632653, 0.8172043, 0.14583333, 0.7173913, 0.6210526, 0.11956522], [10.0, 1.0, 0.1122449, 0.2371134, 0.8958333, 0.19387755, 0.827957, 0.8125, 0.8586956, 0.94736844, 0.48913044], [10.0, 0.19148937, 0.1734694, 0.31958762, 0.29166666, 0.5510204, 0.8064516, 0.6145833, 0.8043478, 1.0, 0.9347826], [10.0, 0.89361703, 0.6122449, 1.0, 0.083333336, 1.0, 0.010752688, 0.8125, 0.23913044, 0.010526316, 0.9782609], [10.0, 0.22340426, 0.59183675, 0.69072163, 0.25, 0.26530612, 0.43010753, 0.28125, 0.4456522, 0.8210526, 0.5217391], [10.0, 0.62765956, 0.18367347, 0.97938144, 0.22916667, 0.7755102, 0.58064514, 0.4375, 0.0, 0.47368422, 0.4347826], [10.0, 0.69148934, 0.5510204, 0.68041235, 0.6666667, 0.36734694, 0.6989247, 0.36458334, 0.6086956, 0.8736842, 0.8043478], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]

node_num = 51
cust_num = 50
stage_num = 10
batch_size = 1


array = np.array(list[:-1])
# origin_test_data为还原后的输入数据
origin_test_data = norm_inverse(array)
print(origin_test_data)
# process_time为测试数据的各阶段加工时间（目前时2阶段）
process_time = []
p_time = origin_test_data.iloc[:, 1:].values.tolist()
process_time.append(p_time)
print("process_time:\n", p_time)

start_time = tf.zeros((stage_num, batch_size, cust_num))
end_time = tf.zeros((stage_num, batch_size, cust_num))
process_time = tf.convert_to_tensor(process_time)

# 各配送中心各阶段作业加工顺序
idx=[[10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27], [10, 31, 45, 6, 49, 26, 36, 34, 28, 15, 44, 14, 19, 24, 39, 12, 32, 47, 30, 38, 20, 18, 22, 46, 23, 8, 1, 35, 0, 3, 9, 48, 33, 42, 43, 13, 25, 16, 41, 21, 2, 40, 4, 7, 11, 5, 37, 17, 29, 27]]


sess = tf.Session()
for stage in range(stage_num):
    stage_id = tf.convert_to_tensor(idx[stage])
    stage_id = tf.expand_dims(stage_id, -1)
    update_start_end_time1(stage_id, stage)

print("start_time:\n", sess.run(start_time))
print("end_time:\n", sess.run(end_time))

print(sess.run(tf.reduce_max(end_time[-1],1)))
# 下面将start_time和end_time存入一维列表
st = np.round(np.squeeze(sess.run(start_time)))
et = np.round(np.squeeze(sess.run(end_time)))
p_array = np.round(np.array(p_time))
count = 0
# 这里解决batch_size=1的情况
machine_array = np.zeros((stage_num, cust_num))
for stage in range(stage_num):
    for index in range(node_num-1):
        if (idx[stage][index]) != cust_num:
            machine_array[stage][idx[stage][index]] = count
    count = count + 1

st_list = []
et_list = []
p_list = []
job_id_list = []
op_list = np.arange(cust_num)
n_bay_start = []

for i in range(stage_num):
    for j in range(cust_num):
        st_list.append(st[i][j])
        et_list.append(et[i][j])
        p_list.append(p_array[j, i])
        job_id_list.append(j)
        n_bay_start.append(machine_array[i][j])

df = pd.DataFrame({'Machine': n_bay_start,
                   'Start': st_list,
                   'Finish': et_list,
                   'Duration': p_list,
                   'job_id': job_id_list})
df.to_csv("gantt_data.csv")
